{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yagor/anaconda3/envs/pyspark_env/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "MASTER = \"local\"\n",
    "NUM_PROCESSORS = \"8\"\n",
    "NUM_EXECUTORS = \"4\"\n",
    "NUM_PARTITIONS = 10\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "import pyspark.sql.functions as psf\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7f00d6ec36d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = SparkConf()\n",
    "\n",
    "conf.set(\"spark.app.name\", \"one_part_data\")\n",
    "conf.set(\"spark.master\", MASTER)\n",
    "conf.set(\"spark.executor.cores\", NUM_PROCESSORS)\n",
    "conf.set(\"spark.executor.instances\", NUM_EXECUTORS)\n",
    "conf.set(\"spark.executor.memory\", \"6g\")\n",
    "conf.set(\"spark.locality.wait\", \"0\")\n",
    "conf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "conf.set(\"spark.kryoserializer.buffer.max\", \"2000\")\n",
    "conf.set(\"spark.executor.heartbeatInterval\", \"6000s\")\n",
    "conf.set(\"spark.network.timeout\", \"10000000s\")\n",
    "conf.set(\"spark.shuffle.spill\", \"true\")\n",
    "conf.set(\"spark.driver.memory\", \"15g\")\n",
    "conf.set(\"spark.driver.maxResultSize\", \"15g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/11 14:01:38 WARN Utils: Your hostname, yagor-pc resolves to a loopback address: 127.0.1.1; using 192.168.0.107 instead (on interface enp7s0)\n",
      "23/01/11 14:01:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/11 14:01:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/01/11 14:01:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.107:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkByExamples.com</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f00c5395210>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "      .config(conf=conf) \\\n",
    "      .master(\"local[*]\") \\\n",
    "      .appName(\"SparkByExamples.com\") \\\n",
    "      .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.read.csv(\"/home/yagor/Рабочий стол/mipt/lab3/notebook/nutrition_table.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------------------+-----------+-------------+---------+-----------+--------------------+-----------------+--------+--------------------+\n",
      "|_c0|fat_100g|carbohydrates_100g|sugars_100g|proteins_100g|salt_100g|energy_100g|reconstructed_energy|            g_sum|exceeded|             product|\n",
      "+---+--------+------------------+-----------+-------------+---------+-----------+--------------------+-----------------+--------+--------------------+\n",
      "|  1|   28.57|             64.29|      14.29|         3.57|      0.0|     2243.0|             2267.85|            96.43|       0|Banana Chips Swee...|\n",
      "|  2|   17.86|             60.71|      17.86|        17.86|    0.635|     1941.0|             2032.23|96.42999999999999|       0|             Peanuts|\n",
      "|  3|   57.14|             17.86|       3.57|        17.86|  1.22428|     2540.0|              2835.7|            92.86|       0|Organic Salted Nu...|\n",
      "|  7|   18.75|             57.81|      15.62|        14.06|   0.1397|     1833.0|             1953.04|            90.62|       0|      Organic Muesli|\n",
      "| 12|   36.67|             36.67|       3.33|        16.67|  1.60782|     2230.0|             2336.91|            90.01|       0|       Zen Party Mix|\n",
      "| 15|   18.18|              60.0|      21.82|        14.55|  0.02286|     1824.0|             1976.37|            92.73|       0|Cinnamon Nut Granola|\n",
      "| 16|   60.71|             17.86|       3.57|        14.29|  0.01016|     2632.0|             2914.24|92.85999999999999|       0|   Organic Hazelnuts|\n",
      "| 19|    5.95|             66.67|       2.38|        16.67|   0.0254|     1096.0|  1648.8300000000002|            89.29|       0|  Organic Oat Groats|\n",
      "| 20|    17.5|              42.5|       32.5|          7.5|  0.28448|     1464.0|              1532.5|             67.5|       0|    Energy Power Mix|\n",
      "| 21|   33.33|             46.67|       30.0|        13.33|  0.46482|     2092.0|             2319.87|            93.33|       0|Antioxidant Mix -...|\n",
      "| 22|   10.91|             69.09|      27.27|        10.91|  0.02286|     1674.0|             1785.49|            90.91|       0|Organic Quinoa Co...|\n",
      "| 23|    50.0|             23.33|       6.67|         6.67|     1.27|     2372.0|              2460.0|             80.0|       0|Fire Roasted Hatc...|\n",
      "| 24|    20.0|              60.0|      33.33|         8.89|  0.19812|     1954.0|             1951.13|            88.89|       0|Peanut Butter Pow...|\n",
      "| 26|   22.22|             57.41|       5.56|        12.96|  0.28194|     1548.0|             2062.87|            92.59|       0|Organic Unswt Ber...|\n",
      "| 27|   46.67|              30.0|       6.67|        16.67|    1.016|     2372.0|             2613.52|            93.34|       0|Roasted Salted Bl...|\n",
      "| 28|   43.33|              30.0|       6.67|        16.67|  1.35382|     2372.0|  2483.2599999999998|             90.0|       0|Thai Curry Roaste...|\n",
      "| 29|   46.67|             23.33|       3.33|         20.0|    2.032|     2230.0|  2556.7400000000002|             90.0|       0|Wasabi Tamari Alm...|\n",
      "| 31|    6.67|             64.44|      11.11|        13.33|  0.01016|     1490.0|  1582.2200000000003|            84.44|       0|  Organic Red Quinoa|\n",
      "| 32|    35.0|              52.5|       37.5|          5.0|    0.127|     2092.0|              2342.5|             92.5|       0|Dark Chocolate Co...|\n",
      "| 34|   21.57|             58.82|       3.92|        11.76|  0.27432|     1887.0|  2041.0900000000001|            92.15|       0|Organic Unsweeten...|\n",
      "+---+--------+------------------+-----------+-------------+---------+-----------+--------------------+-----------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [ #'_c0',\n",
    " 'fat_100g',\n",
    " 'carbohydrates_100g',\n",
    " 'sugars_100g',\n",
    " 'proteins_100g',\n",
    " 'salt_100g',\n",
    " 'energy_100g',\n",
    " 'reconstructed_energy',\n",
    " 'g_sum',\n",
    " 'exceeded',\n",
    " #'product'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assembler = VectorAssembler(inputCols = feat_cols, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = vec_assembler.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------------------+-----------+-------------+---------+-----------+--------------------+-----------------+--------+--------------------+--------------------+\n",
      "|_c0|fat_100g|carbohydrates_100g|sugars_100g|proteins_100g|salt_100g|energy_100g|reconstructed_energy|            g_sum|exceeded|             product|            features|\n",
      "+---+--------+------------------+-----------+-------------+---------+-----------+--------------------+-----------------+--------+--------------------+--------------------+\n",
      "|  1|   28.57|             64.29|      14.29|         3.57|      0.0|     2243.0|             2267.85|            96.43|       0|Banana Chips Swee...|[28.57,64.29,14.2...|\n",
      "|  2|   17.86|             60.71|      17.86|        17.86|    0.635|     1941.0|             2032.23|96.42999999999999|       0|             Peanuts|[17.86,60.71,17.8...|\n",
      "|  3|   57.14|             17.86|       3.57|        17.86|  1.22428|     2540.0|              2835.7|            92.86|       0|Organic Salted Nu...|[57.14,17.86,3.57...|\n",
      "|  7|   18.75|             57.81|      15.62|        14.06|   0.1397|     1833.0|             1953.04|            90.62|       0|      Organic Muesli|[18.75,57.81,15.6...|\n",
      "| 12|   36.67|             36.67|       3.33|        16.67|  1.60782|     2230.0|             2336.91|            90.01|       0|       Zen Party Mix|[36.67,36.67,3.33...|\n",
      "| 15|   18.18|              60.0|      21.82|        14.55|  0.02286|     1824.0|             1976.37|            92.73|       0|Cinnamon Nut Granola|[18.18,60.0,21.82...|\n",
      "| 16|   60.71|             17.86|       3.57|        14.29|  0.01016|     2632.0|             2914.24|92.85999999999999|       0|   Organic Hazelnuts|[60.71,17.86,3.57...|\n",
      "| 19|    5.95|             66.67|       2.38|        16.67|   0.0254|     1096.0|  1648.8300000000002|            89.29|       0|  Organic Oat Groats|[5.95,66.67,2.38,...|\n",
      "| 20|    17.5|              42.5|       32.5|          7.5|  0.28448|     1464.0|              1532.5|             67.5|       0|    Energy Power Mix|[17.5,42.5,32.5,7...|\n",
      "| 21|   33.33|             46.67|       30.0|        13.33|  0.46482|     2092.0|             2319.87|            93.33|       0|Antioxidant Mix -...|[33.33,46.67,30.0...|\n",
      "| 22|   10.91|             69.09|      27.27|        10.91|  0.02286|     1674.0|             1785.49|            90.91|       0|Organic Quinoa Co...|[10.91,69.09,27.2...|\n",
      "| 23|    50.0|             23.33|       6.67|         6.67|     1.27|     2372.0|              2460.0|             80.0|       0|Fire Roasted Hatc...|[50.0,23.33,6.67,...|\n",
      "| 24|    20.0|              60.0|      33.33|         8.89|  0.19812|     1954.0|             1951.13|            88.89|       0|Peanut Butter Pow...|[20.0,60.0,33.33,...|\n",
      "| 26|   22.22|             57.41|       5.56|        12.96|  0.28194|     1548.0|             2062.87|            92.59|       0|Organic Unswt Ber...|[22.22,57.41,5.56...|\n",
      "| 27|   46.67|              30.0|       6.67|        16.67|    1.016|     2372.0|             2613.52|            93.34|       0|Roasted Salted Bl...|[46.67,30.0,6.67,...|\n",
      "| 28|   43.33|              30.0|       6.67|        16.67|  1.35382|     2372.0|  2483.2599999999998|             90.0|       0|Thai Curry Roaste...|[43.33,30.0,6.67,...|\n",
      "| 29|   46.67|             23.33|       3.33|         20.0|    2.032|     2230.0|  2556.7400000000002|             90.0|       0|Wasabi Tamari Alm...|[46.67,23.33,3.33...|\n",
      "| 31|    6.67|             64.44|      11.11|        13.33|  0.01016|     1490.0|  1582.2200000000003|            84.44|       0|  Organic Red Quinoa|[6.67,64.44,11.11...|\n",
      "| 32|    35.0|              52.5|       37.5|          5.0|    0.127|     2092.0|              2342.5|             92.5|       0|Dark Chocolate Co...|[35.0,52.5,37.5,5...|\n",
      "| 34|   21.57|             58.82|       3.92|        11.76|  0.27432|     1887.0|  2041.0900000000001|            92.15|       0|Organic Unsweeten...|[21.57,58.82,3.92...|\n",
      "+---+--------+------------------+-----------+-------------+---------+-----------+--------------------+-----------------+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, fat_100g: double, carbohydrates_100g: double, sugars_100g: double, proteins_100g: double, salt_100g: double, energy_100g: double, reconstructed_energy: double, g_sum: double, exceeded: int, product: string, features: vector]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics by fitting the StandardScaler\n",
    "scalerModel = scaler.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize each feature to have unit standard deviation.\n",
    "cluster_final_data = scalerModel.transform(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With K=2\n",
      "Silhouette with squared euclidean distance = 0.7668198339263336\n",
      "------------------------------------------------------------\n",
      "With K=3\n",
      "Silhouette with squared euclidean distance = 0.7630900317357944\n",
      "------------------------------------------------------------\n",
      "With K=4\n",
      "Silhouette with squared euclidean distance = 0.45382779775000187\n",
      "------------------------------------------------------------\n",
      "With K=5\n",
      "Silhouette with squared euclidean distance = 0.5329292075618965\n",
      "------------------------------------------------------------\n",
      "With K=6\n",
      "Silhouette with squared euclidean distance = 0.2752095921075341\n",
      "------------------------------------------------------------\n",
      "With K=7\n",
      "Silhouette with squared euclidean distance = 0.27855535014230576\n",
      "------------------------------------------------------------\n",
      "With K=8\n",
      "Silhouette with squared euclidean distance = 0.32041363209041773\n",
      "------------------------------------------------------------\n",
      "With K=9\n",
      "Silhouette with squared euclidean distance = 0.3383731965051368\n",
      "------------------------------------------------------------\n",
      "With K=10\n",
      "Silhouette with squared euclidean distance = 0.24026315004840737\n",
      "------------------------------------------------------------\n",
      "With K=11\n",
      "Silhouette with squared euclidean distance = 0.24104168542556068\n",
      "------------------------------------------------------------\n",
      "With K=12\n",
      "Silhouette with squared euclidean distance = 0.19591978002619206\n",
      "------------------------------------------------------------\n",
      "With K=13\n",
      "Silhouette with squared euclidean distance = 0.283084180485783\n",
      "------------------------------------------------------------\n",
      "With K=14\n",
      "Silhouette with squared euclidean distance = 0.19760825201359156\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for k in range(2,15):\n",
    "    kmeans = KMeans(featuresCol='scaledFeatures',k=k)\n",
    "    model = kmeans.fit(cluster_final_data)\n",
    "    predictions = model.transform(cluster_final_data)\n",
    "    evaluator = ClusteringEvaluator()\n",
    "    silhouette = evaluator.evaluate(predictions)\n",
    "    print(\"With K={}\".format(k))\n",
    "    print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
    "    print('--'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "\n",
    "kmeans = KMeans(featuresCol='scaledFeatures', predictionCol='pred_kmeans_cluster', k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKMeans = kmeans.fit(cluster_final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = modelKMeans.transform(cluster_final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split on train and test and analys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------------------+-----------+-------------+---------+-----------+--------------------+-----------------+--------+--------------------+--------------------+--------------------+-------------------+\n",
      "|_c0|fat_100g|carbohydrates_100g|sugars_100g|proteins_100g|salt_100g|energy_100g|reconstructed_energy|            g_sum|exceeded|             product|            features|      scaledFeatures|pred_kmeans_cluster|\n",
      "+---+--------+------------------+-----------+-------------+---------+-----------+--------------------+-----------------+--------+--------------------+--------------------+--------------------+-------------------+\n",
      "|  1|   28.57|             64.29|      14.29|         3.57|      0.0|     2243.0|             2267.85|            96.43|       0|Banana Chips Swee...|[28.57,64.29,14.2...|[1.91358558312757...|                  0|\n",
      "|  2|   17.86|             60.71|      17.86|        17.86|    0.635|     1941.0|             2032.23|96.42999999999999|       0|             Peanuts|[17.86,60.71,17.8...|[1.19624216012105...|                  0|\n",
      "|  3|   57.14|             17.86|       3.57|        17.86|  1.22428|     2540.0|              2835.7|            92.86|       0|Organic Salted Nu...|[57.14,17.86,3.57...|[3.82717116625514...|                  0|\n",
      "|  7|   18.75|             57.81|      15.62|        14.06|   0.1397|     1833.0|             1953.04|            90.62|       0|      Organic Muesli|[18.75,57.81,15.6...|[1.25585333159404...|                  0|\n",
      "| 12|   36.67|             36.67|       3.33|        16.67|  1.60782|     2230.0|             2336.91|            90.01|       0|       Zen Party Mix|[36.67,36.67,3.33...|[2.4561142223762,...|                  0|\n",
      "| 15|   18.18|              60.0|      21.82|        14.55|  0.02286|     1824.0|             1976.37|            92.73|       0|Cinnamon Nut Granola|[18.18,60.0,21.82...|[1.21767539031358...|                  0|\n",
      "| 16|   60.71|             17.86|       3.57|        14.29|  0.01016|     2632.0|             2914.24|92.85999999999999|       0|   Organic Hazelnuts|[60.71,17.86,3.57...|[4.06628564059064...|                  0|\n",
      "| 19|    5.95|             66.67|       2.38|        16.67|   0.0254|     1096.0|  1648.8300000000002|            89.29|       0|  Organic Oat Groats|[5.95,66.67,2.38,...|[0.39852412389251...|                  0|\n",
      "| 20|    17.5|              42.5|       32.5|          7.5|  0.28448|     1464.0|              1532.5|             67.5|       0|    Energy Power Mix|[17.5,42.5,32.5,7...|[1.17212977615444...|                  0|\n",
      "| 21|   33.33|             46.67|       30.0|        13.33|  0.46482|     2092.0|             2319.87|            93.33|       0|Antioxidant Mix -...|[33.33,46.67,30.0...|[2.23240488224158...|                  0|\n",
      "| 22|   10.91|             69.09|      27.27|        10.91|  0.02286|     1674.0|             1785.49|            90.91|       0|Organic Quinoa Co...|[10.91,69.09,27.2...|[0.73073919187685...|                  0|\n",
      "| 23|    50.0|             23.33|       6.67|         6.67|     1.27|     2372.0|              2460.0|             80.0|       0|Fire Roasted Hatc...|[50.0,23.33,6.67,...|[3.34894221758412...|                  0|\n",
      "| 24|    20.0|              60.0|      33.33|         8.89|  0.19812|     1954.0|             1951.13|            88.89|       0|Peanut Butter Pow...|[20.0,60.0,33.33,...|[1.33957688703365...|                  0|\n",
      "| 26|   22.22|             57.41|       5.56|        12.96|  0.28194|     1548.0|             2062.87|            92.59|       0|Organic Unswt Ber...|[22.22,57.41,5.56...|[1.48826992149438...|                  0|\n",
      "| 27|   46.67|              30.0|       6.67|        16.67|    1.016|     2372.0|             2613.52|            93.34|       0|Roasted Salted Bl...|[46.67,30.0,6.67,...|[3.12590266589302...|                  0|\n",
      "| 28|   43.33|              30.0|       6.67|        16.67|  1.35382|     2372.0|  2483.2599999999998|             90.0|       0|Thai Curry Roaste...|[43.33,30.0,6.67,...|[2.90219332575840...|                  0|\n",
      "| 29|   46.67|             23.33|       3.33|         20.0|    2.032|     2230.0|  2556.7400000000002|             90.0|       0|Wasabi Tamari Alm...|[46.67,23.33,3.33...|[3.12590266589302...|                  0|\n",
      "| 31|    6.67|             64.44|      11.11|        13.33|  0.01016|     1490.0|  1582.2200000000003|            84.44|       0|  Organic Red Quinoa|[6.67,64.44,11.11...|[0.44674889182572...|                  0|\n",
      "| 32|    35.0|              52.5|       37.5|          5.0|    0.127|     2092.0|              2342.5|             92.5|       0|Dark Chocolate Co...|[35.0,52.5,37.5,5...|[2.34425955230889...|                  0|\n",
      "| 34|   21.57|             58.82|       3.92|        11.76|  0.27432|     1887.0|  2041.0900000000001|            92.15|       0|Organic Unsweeten...|[21.57,58.82,3.92...|[1.44473367266579...|                  0|\n",
      "+---+--------+------------------+-----------+-------------+---------+-----------+--------------------+-----------------+--------+--------------------+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ClusteringEvaluator(predictionCol='pred_kmeans_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With k=2 Silhouette with squared euclidean distance = 0.7668198339263336\n"
     ]
    }
   ],
   "source": [
    "print(f\"With k={k} Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers:\n",
      "[1.19486632 1.8629406  1.15892678 1.16388705 0.11194177 2.2653329\n",
      " 2.25972459 2.41225435 0.18817334]\n",
      "[0.24865497 0.44342242 0.33145447 0.50509242 0.11777061 0.58014115\n",
      " 0.55044094 0.61165374 0.        ]\n"
     ]
    }
   ],
   "source": [
    "centers=modelKMeans.clusterCenters()\n",
    "print(\"Cluster Centers:\")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|pred_kmeans_cluster|count|\n",
      "+-------------------+-----+\n",
      "|                  1|22546|\n",
      "|                  0|22482|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelKMeans.transform(cluster_final_data).groupBy('pred_kmeans_cluster').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"_c0\", \"pred_kmeans_cluster\"]\n",
    "result = predictions.select(*cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "|_c0|pred_kmeans_cluster|\n",
      "+---+-------------------+\n",
      "|  1|                  0|\n",
      "|  2|                  0|\n",
      "|  3|                  0|\n",
      "|  7|                  0|\n",
      "| 12|                  0|\n",
      "| 15|                  0|\n",
      "| 16|                  0|\n",
      "| 19|                  0|\n",
      "| 20|                  0|\n",
      "| 21|                  0|\n",
      "| 22|                  0|\n",
      "| 23|                  0|\n",
      "| 24|                  0|\n",
      "| 26|                  0|\n",
      "| 27|                  0|\n",
      "| 28|                  0|\n",
      "| 29|                  0|\n",
      "| 31|                  0|\n",
      "| 32|                  0|\n",
      "| 34|                  0|\n",
      "+---+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = predictions.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|pred_kmeans_cluster|count|\n",
      "+-------------------+-----+\n",
      "|                  1|15727|\n",
      "|                  0|15742|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.groupBy('pred_kmeans_cluster').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13559"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31469"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier, RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest = RandomForestClassifier(labelCol=\"pred_kmeans_cluster\", featuresCol=\"scaledFeatures\", \\\n",
    "                        predictionCol='pred_from_randomforest_class', numTrees=20, maxDepth=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRandomForest = RandomForest.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions_RandomForest = modelRandomForest.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------------------+--------------------+\n",
      "|pred_from_randomforest_class|pred_kmeans_cluster|      scaledFeatures|\n",
      "+----------------------------+-------------------+--------------------+\n",
      "|                         0.0|                  0|[1.91358558312757...|\n",
      "|                         0.0|                  0|[2.4561142223762,...|\n",
      "|                         0.0|                  0|[0.39852412389251...|\n",
      "|                         0.0|                  0|[1.33957688703365...|\n",
      "|                         0.0|                  0|[3.12590266589302...|\n",
      "+----------------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.0150454\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select example rows to display.\n",
    "predictions_RandomForest.select(\"pred_from_randomforest_class\", \"pred_kmeans_cluster\", \"scaledFeatures\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"pred_kmeans_cluster\", predictionCol=\"pred_from_randomforest_class\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions_RandomForest)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "|pred_from_randomforest_class|pred_kmeans_cluster|      scaledFeatures|       rawPrediction|         probability|\n",
      "+----------------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "|                         0.0|                  0|[1.91358558312757...|[19.6653915832780...|[0.98326957916390...|\n",
      "|                         0.0|                  0|[2.4561142223762,...|[19.6181705200750...|[0.98090852600375...|\n",
      "|                         0.0|                  0|[0.39852412389251...|[19.1479398846721...|[0.95739699423360...|\n",
      "|                         0.0|                  0|[1.33957688703365...|[19.7516364636404...|[0.98758182318202...|\n",
      "|                         0.0|                  0|[3.12590266589302...|[19.6021880065115...|[0.98010940032557...|\n",
      "+----------------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions_RandomForest.select(\"pred_from_randomforest_class\", \"pred_kmeans_cluster\", \"scaledFeatures\", 'rawPrediction', 'probability').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----+\n",
      "|pred_from_randomforest_class|count|\n",
      "+----------------------------+-----+\n",
      "|                         0.0| 6806|\n",
      "|                         1.0| 6753|\n",
      "+----------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_RandomForest.groupBy('pred_from_randomforest_class').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRandomForest = RandomForest.fit(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions_RandomForest = modelRandomForest.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------------------+--------------------+\n",
      "|pred_from_randomforest_class|pred_kmeans_cluster|      scaledFeatures|\n",
      "+----------------------------+-------------------+--------------------+\n",
      "|                         0.0|                  0|[1.91358558312757...|\n",
      "|                         0.0|                  0|[2.4561142223762,...|\n",
      "|                         0.0|                  0|[0.39852412389251...|\n",
      "|                         0.0|                  0|[1.33957688703365...|\n",
      "|                         0.0|                  0|[3.12590266589302...|\n",
      "+----------------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.0144553\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select example rows to display.\n",
    "predictions_RandomForest.select(\"pred_from_randomforest_class\", \"pred_kmeans_cluster\", \"scaledFeatures\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"pred_kmeans_cluster\", predictionCol=\"pred_from_randomforest_class\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions_RandomForest)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "|pred_from_randomforest_class|pred_kmeans_cluster|      scaledFeatures|       rawPrediction|         probability|\n",
      "+----------------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "|                         0.0|                  0|[1.91358558312757...|[19.5958653690484...|[0.97979326845242...|\n",
      "|                         0.0|                  0|[2.4561142223762,...|[19.4051662509886...|[0.97025831254943...|\n",
      "|                         0.0|                  0|[0.39852412389251...|[19.1860806411448...|[0.95930403205724...|\n",
      "|                         0.0|                  0|[1.33957688703365...|[19.7294927338896...|[0.98647463669448...|\n",
      "|                         0.0|                  0|[3.12590266589302...|[19.3358259609285...|[0.96679129804642...|\n",
      "+----------------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions_RandomForest.select(\"pred_from_randomforest_class\", \"pred_kmeans_cluster\", \"scaledFeatures\", 'rawPrediction', 'probability').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----+\n",
      "|pred_from_randomforest_class|count|\n",
      "+----------------------------+-----+\n",
      "|                         0.0| 6860|\n",
      "|                         1.0| 6699|\n",
      "+----------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_RandomForest.groupBy('pred_from_randomforest_class').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear regression model and propability (logostic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinRegression = LinearRegression(maxIter=30, regParam=0.1, elasticNetParam=0.1, labelCol=\"pred_from_randomforest_class\", featuresCol=\"scaledFeatures\")\n",
    "\n",
    "# # Fit the model\n",
    "# modelLinearRegression = LinRegression.fit(predictions_RandomForest)\n",
    "\n",
    "# # Print the coefficients and intercept for linear regression\n",
    "# print(\"Coefficients: %s\" % str(modelLinearRegression.coefficients))\n",
    "# print(\"Intercept: %s\" % str(modelLinearRegression.intercept))\n",
    "\n",
    "# # Summarize the model over the training set and print out some metrics\n",
    "# trainingSummary = modelLinearRegression.summary\n",
    "# print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "# print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "# trainingSummary.residuals.show()\n",
    "# print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "# print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['rawPrediction', 'probability']\n",
    "predictions_RandomForest = predictions_RandomForest.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegression = LogisticRegression(maxIter=10, regParam=0.1, elasticNetParam=1.0, labelCol=\"pred_from_randomforest_class\", featuresCol=\"scaledFeatures\", probabilityCol=\"lr_prob\", predictionCol='pred_from_logregression_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = LogRegression.fit(predictions_RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      "1 X 9 CSRMatrix\n",
      "(0,5) -0.2434\n",
      "(0,6) -0.5471\n",
      "(0,7) -1.1639\n",
      "Intercept: [2.810568922526613]\n",
      "objectiveHistory:\n",
      "0.693076682585191\n",
      "0.645808998874504\n",
      "0.44833530734612487\n",
      "0.4278920355836153\n",
      "0.4198770993521608\n",
      "0.41804537105492373\n",
      "0.4130563875037308\n",
      "0.4125837510695403\n",
      "0.4118426040514606\n",
      "0.4100892941057106\n",
      "0.40952883776409743\n",
      "False positive rate by label:\n",
      "label 0: 0.01671891327063741\n",
      "label 1: 0.019533527696793004\n",
      "True positive rate by label:\n",
      "label 0: 0.980466472303207\n",
      "label 1: 0.9832810867293625\n",
      "Precision by label:\n",
      "label 0: 0.9836209417958467\n",
      "label 1: 0.9800624907007885\n",
      "Recall by label:\n",
      "label 0: 0.980466472303207\n",
      "label 1: 0.9832810867293625\n",
      "F-measure by label:\n",
      "label 0: 0.982041173893999\n",
      "label 1: 0.9816691505216095\n",
      "Accuracy: 0.9818570691053913\n",
      "FPR: 0.018109510072821668\n",
      "TPR: 0.9818570691053912\n",
      "F-measure: 0.98185737091652\n",
      "Precision: 0.9818628428294189\n",
      "Recall: 0.9818570691053912\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for multinomial logistic regression\n",
    "print(\"Coefficients: \\n\" + str(lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel.interceptVector))\n",
    "\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.sql import DataFrame\n",
    "from typing import Iterable\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM TRANSFORMER ----------------------------------------------------------------\n",
    "class ColumnDropper(Transformer):\n",
    "    \"\"\"\n",
    "    A custom Transformer which drops all columns that have at least one of the\n",
    "    words from the banned_list in the name.\n",
    "    \"\"\"\n",
    "    def __init__(self, banned_list: Iterable[str]):\n",
    "        super(ColumnDropper, self).__init__()\n",
    "        self.banned_list = banned_list\n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        df = df.drop(*[x for x in df.columns if any(y in x for y in self.banned_list)])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dropper = ColumnDropper(banned_list = ['rawPrediction', 'probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assembler = VectorAssembler(inputCols = feat_cols, outputCol='features')\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "kmeans = KMeans(featuresCol='scaledFeatures', predictionCol='pred_kmeans_cluster', k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest = RandomForestClassifier(labelCol=\"pred_kmeans_cluster\", featuresCol=\"scaledFeatures\", predictionCol='pred_from_randomforest_class', numTrees=20, maxDepth=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogRegression = LogisticRegression(maxIter=10, regParam=0.1, elasticNetParam=1.0, labelCol=\"pred_from_randomforest_class\", \\\n",
    "featuresCol=\"scaledFeatures\", probabilityCol=\"lr_prob\", predictionCol='pred_from_logregression_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[vec_assembler, scaler, kmeans, RandomForest, column_dropper, LogRegression])\n",
    "\n",
    "model = pipeline.fit(trainingData)\n",
    "output = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With k=2 Silhouette with squared euclidean distance = 0.33976540615883033\n",
      "+-------------------+-----+\n",
      "|pred_kmeans_cluster|count|\n",
      "+-------------------+-----+\n",
      "|                  1| 6794|\n",
      "|                  0| 6827|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = ClusteringEvaluator(predictionCol='pred_kmeans_cluster', featuresCol='scaledFeatures')\n",
    "silhouette = evaluator.evaluate(output)\n",
    "print(f\"With k={k} Silhouette with squared euclidean distance = \" + str(silhouette))\n",
    "output.groupBy('pred_kmeans_cluster').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0147566\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"pred_kmeans_cluster\", predictionCol=\"pred_from_randomforest_class\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(output)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      6827\n",
      "           1       0.99      0.98      0.99      6794\n",
      "\n",
      "    accuracy                           0.99     13621\n",
      "   macro avg       0.99      0.99      0.99     13621\n",
      "weighted avg       0.99      0.99      0.99     13621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = output.select(['pred_kmeans_cluster']).collect()\n",
    "y_pred = output.select(['pred_from_randomforest_class']).collect()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid=LogisticRegression_b7dbaa45e054, numClasses=2, numFeatures=9"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      "1 X 9 CSRMatrix\n",
      "(0,5) -0.4503\n",
      "(0,6) -0.65\n",
      "(0,7) -1.045\n",
      "Intercept: [3.092357938841986]\n",
      "objectiveHistory:\n",
      "0.693146409574009\n",
      "0.6459304743256445\n",
      "0.44815434558424794\n",
      "0.4275511517897116\n",
      "0.4199204817416282\n",
      "0.41832222831473115\n",
      "0.4169196662780055\n",
      "0.4137765716338624\n",
      "0.4131883506284702\n",
      "0.4125110577394595\n",
      "0.4116716198314688\n",
      "False positive rate by label:\n",
      "label 0: 0.016131089007906146\n",
      "label 1: 0.0026076448514914456\n",
      "True positive rate by label:\n",
      "label 0: 0.9973923551485085\n",
      "label 1: 0.9838689109920938\n",
      "Precision by label:\n",
      "label 0: 0.9841229996862253\n",
      "label 1: 0.9973500517063082\n",
      "Recall by label:\n",
      "label 0: 0.9973923551485085\n",
      "label 1: 0.9838689109920938\n",
      "F-measure by label:\n",
      "label 0: 0.9907132478362499\n",
      "label 1: 0.9905636153549878\n",
      "Accuracy: 0.990639029515713\n",
      "FPR: 0.009377763375110648\n",
      "TPR: 0.990639029515713\n",
      "F-measure: 0.9906385244995379\n",
      "Precision: 0.9907283132750107\n",
      "Recall: 0.990639029515713\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for multinomial logistic regression\n",
    "print(\"Coefficients: \\n\" + str(model.stages[5].coefficientMatrix))\n",
    "print(\"Intercept: \" + str(model.stages[5].interceptVector))\n",
    "\n",
    "trainingSummary = model.stages[5].summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yagor/anaconda3/envs/pyspark_env/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "predict = model.transform(testData)\n",
    "\n",
    "df_normed = predict.rdd.map(lambda x: (x['pred_from_logregression_class'], x['lr_prob'])) \\\n",
    "    .reduceByKey(add).toDF(['pred_from_logregression_class', 'lr_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification mean propability confidence for classes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yagor/anaconda3/envs/pyspark_env/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0: 0.8281598623016101\n",
      "label 1: 0.8364402755714606\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "\n",
    "normilize = Normalizer(inputCol='lr_prob', outputCol='normilize', p=1)\n",
    "norm = normilize.transform(df_normed).rdd.map(lambda x: (x['pred_from_logregression_class'], x['normilize'].toArray().max()))\n",
    "\n",
    "print('Classification mean propability confidence for classes:')\n",
    "for label, confidence in norm.collect():\n",
    "    print(f'label {int(label)}: {confidence}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pyspark_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fbacc38e156424bc4feb2fa78cad4dfa544bcce4e4fb367bb488859be726019"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
